{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pdf2image\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "from transformers import pipeline\n",
    "import docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if \"OS\" in os.environ.keys() and \"WINDOWS\" in os.environ[\"OS\"].upper():\n",
    "    OS=\"WINDOWS\"\n",
    "    pytesseract.pytesseract.tesseract_cmd = (\n",
    "        r\"C:\\Users\\conrad.thiounn\\AppData\\Local\\Programs\\Tesseract-OCR\\tesseract.exe\"\n",
    "    )\n",
    "    POPPLER_PATH = r\"C:\\Users\\conrad.thiounn\\Desktop\\poppler-23.01.0\\Library\\bin\"\n",
    "else:\n",
    "    OS=\"UNIX\"\n",
    "    pytesseract.pytesseract.tesseract_cmd = (\n",
    "        r\"/usr/bin/tesseract\"\n",
    "    )\n",
    "    POPPLER_PATH = r\"/usr/share/poppler\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_BASE_DIR=\"./\"\n",
    "NAME_OF_PDF_FILE_TO_READ=\"arrete_jury_composition_Administrateur_ENS_2023.pdf\"\n",
    "FULL_PATH_PDF_FILE=DATA_BASE_DIR+NAME_OF_PDF_FILE_TO_READ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/34837707/how-to-extract-text-from-a-pdf-file\n",
    "def read_pdf(pdf_file_path: str) -> str:\n",
    "    # First, create an opener which accepts a PDF file path\n",
    "    opener = open(pdf_file_path, \"rb\")\n",
    "    # Second, read the opened file\n",
    "    pdf_file_reader = PyPDF2.PdfReader(opener)\n",
    "    number_of_pages = len(pdf_file_reader.pages)\n",
    "    text = \"\"\n",
    "    for i in range(number_of_pages):\n",
    "        page = pdf_file_reader.pages[i]\n",
    "        text += page.extract_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/64048828/pytesseract-gives-an-error-permissionerror-winerror-5-access-is-denied\n",
    "def read_and_print_pdf_with_ocr(pdf_file_path: str,lang:str=None) -> None:\n",
    "    def pdf_to_img(pdf_file):\n",
    "        return pdf2image.convert_from_path(pdf_file)\n",
    "\n",
    "    def ocr_core(file):\n",
    "        if lang:\n",
    "            text = pytesseract.image_to_string(file, lang=lang)\n",
    "        else:\n",
    "            text = pytesseract.image_to_string(file)\n",
    "        return text\n",
    "\n",
    "    def print_pages(pdf_file):\n",
    "        text=\"\"\n",
    "        images = pdf_to_img(pdf_file)\n",
    "        for pg, img in enumerate(images):\n",
    "            text+=ocr_core(img)\n",
    "        return text\n",
    "\n",
    "    return print_pages(pdf_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/58613880/python-grab-all-text-in-docx-and-dump-into-txt\n",
    "def read_txt_from_docx(filename: str) -> str:\n",
    "    doc = docx.Document(filename)\n",
    "    fullText = []\n",
    "    for para in doc.paragraphs:\n",
    "        fullText.append(para.text)\n",
    "    return \"\\n\".join(fullText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_from_ocr=read_and_print_pdf_with_ocr(FULL_PATH_PDF_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "ARTICLE = \"\"\"\n",
    "Rapidité, qualité et lisibilité, tels sont les besoins des citoyens en matière de prise d'informations. L'Insee et les Services Statistiques Ministériels (SSM), dont la Dares, ont pour ambition de réduire les délais de production et de diffusion des statistiques, comme déclaré dans le plan stratégique \"Insee 2025\". Pour cela, les conclusions de ce plan mettent en exergue la nécessité de mobiliser de nouvelles sources, ainsi que d'enrichir les sources existantes pour permettre de réduire les délais et de diminuer les coûts.\n",
    "La direction de l'animation de la recherche, des études et des statistiques (Dares), SSM du ministère en charge du travail et de l'emploi, produit et diffuse à un rythme régulier des chiffres en matière d'emploi, de chômage, de salaire et de conditions de travail, tout en étant accompagnés d'études pour comprendre le chiffre. Pour comprendre le marché du travail, il est important de comprendre chaque pan du tissu économique, chaque secteur et branche de l'économie française. L'observation des accords entre agents économiques permet de mieux saisir les enjeux d'aujourd'hui et de demain.\n",
    "En grand nombre, une matière première évidente est la juridiction du monde de l'entreprise, composée d'accords collectifs, qu'ils soient de branche ou d'entreprise. Ces accords complètent le code du travail et sont le fruit d'une négociation mûrement réfléchie entre acteurs du monde professionnel. Aujourd'hui, ces accords sont largement sous-exploitées dans la production et l'analyse des chiffres produits par la Dares, compte tenu de la complexité à traiter de manière automatique des documents numériques hétérogènes et à y piocher l'information pertinente.\n",
    "Notamment, reconstituer un sommaire depuis un document numérique, scanné ou typographié, permettrait de gagner en lisibilité et de donner accès rapidement à une vue d'ensemble. Pour aller plus loin, produire un résumé permettrait de faciliter l'analyse de données et donc la production du chiffre.\n",
    "Les dernières méthodes d'apprentissage statistique en traitement automatique du langage permettent de réduire cette complexité, en proposant des modèles génériques déjà entraînés. Il suffirait de réutiliser ces modèles en composant intelligemment, de les améliorer avec des données spécifiques.\n",
    "Concevoir et produire un modèle en adéquation avec le besoin exprimé par la Dares est une première étape cruciale. Néanmoins, pour pérenniser l'investissement, la seconde étape est de le mettre en production dans les règles de l'art.\n",
    "\"\"\"\n",
    "print(summarizer(ARTICLE, max_length=1000, min_length=300, do_sample=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "!python -m spacy download fr_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"fr_core_news_lg\")\n",
    "sentence = txt_from_ocr\n",
    "doc = nlp(sentence)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text,\" - \", ent.label_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
